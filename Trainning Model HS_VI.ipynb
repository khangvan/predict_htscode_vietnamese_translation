{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIEU THUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bieuthue=pd.read_excel(fr\"\\\\vnmsrv300\\Grpfiles\\Document Control\\Internal Document\\Description VI & HS Code\\2018 Change\\bieuthue2019_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=bieuthue.iloc[:,[0,1,2,3]]\n",
    "df.columns=['level','hscode','vi','eng']\n",
    "df['hscode'] = df['hscode'].astype('str')\n",
    "newbieuthue=df\n",
    "\n",
    "# please proces data to show update -temp to skip this step\n",
    "#mask = (df['hscode'].str.len() >=8)\n",
    "#newbieuthue = df.loc[mask]\n",
    "\n",
    "newbieuthue.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "my_report_name ='bieuthue2019'\n",
    "pickle.dump(newbieuthue, open(my_report_name, 'wb')) # disable to prevent kill my model\n",
    "# clsf_report.to_excel(my_report_name+\".xlsx\",engine='xlsxwriter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>hscode</th>\n",
       "      <th>vi</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Phần I</td>\n",
       "      <td>Section I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ĐỘNG VẬT SỐNG; CÁC SẢN PHẨM TỪ ĐỘNG VẬT</td>\n",
       "      <td>LIVE ANIMALS; ANIMAL PRODUCTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Chú giải.</td>\n",
       "      <td>Notes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1. Trong phần này, khi đề cập đến một giống ho...</td>\n",
       "      <td>1. Any reference in this Section to a particul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2. Trừ khi có yêu cầu khác, trong toàn bộ Danh...</td>\n",
       "      <td>2. Except where the context otherwise requires...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Chương 1</td>\n",
       "      <td>Chapter 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ĐỘNG VẬT SỐNG</td>\n",
       "      <td>LIVE ANIMALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Chú giải.</td>\n",
       "      <td>Note.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1. Chương này bao gồm tất cả các loại động vật...</td>\n",
       "      <td>1. This Chapter covers all live animals except:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level hscode                                                 vi  \\\n",
       "0      1      2                                                  3   \n",
       "1      1      2                                             Phần I   \n",
       "2      1      2            ĐỘNG VẬT SỐNG; CÁC SẢN PHẨM TỪ ĐỘNG VẬT   \n",
       "3      1      2                                          Chú giải.   \n",
       "4      1      2  1. Trong phần này, khi đề cập đến một giống ho...   \n",
       "5      1      2  2. Trừ khi có yêu cầu khác, trong toàn bộ Danh...   \n",
       "6      1      2                                           Chương 1   \n",
       "7      1      2                                      ĐỘNG VẬT SỐNG   \n",
       "8      1      2                                          Chú giải.   \n",
       "9      1      2  1. Chương này bao gồm tất cả các loại động vật...   \n",
       "\n",
       "                                                 eng  \n",
       "0                                                  4  \n",
       "1                                          Section I  \n",
       "2                      LIVE ANIMALS; ANIMAL PRODUCTS  \n",
       "3                                             Notes.  \n",
       "4  1. Any reference in this Section to a particul...  \n",
       "5  2. Except where the context otherwise requires...  \n",
       "6                                          Chapter 1  \n",
       "7                                       LIVE ANIMALS  \n",
       "8                                              Note.  \n",
       "9    1. This Chapter covers all live animals except:  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "readbieuthue = pickle.load(open('bieuthue2019', 'rb'))\n",
    "readbieuthue.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION SYS FOR HS CODE AND VIETNAMESE TRANSLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T01:36:46.425929Z",
     "start_time": "2019-10-01T01:35:49.626873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14653, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn</th>\n",
       "      <th>text</th>\n",
       "      <th>target_vi</th>\n",
       "      <th>target_hs</th>\n",
       "      <th>pn_text</th>\n",
       "      <th>text_vi</th>\n",
       "      <th>text_hs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010154002</td>\n",
       "      <td>SCREW  X WN WZ POZI</td>\n",
       "      <td>ỐC VÍT</td>\n",
       "      <td>73181500</td>\n",
       "      <td>010</td>\n",
       "      <td>SCREW  X WN WZ POZI 010</td>\n",
       "      <td>SCREW  X WN WZ POZI 010 ỐC VÍT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>019260044</td>\n",
       "      <td>BAG ANTI-STATIC SHPG SP</td>\n",
       "      <td>TÚI ĐÓNG GÓI</td>\n",
       "      <td>39239090</td>\n",
       "      <td>019</td>\n",
       "      <td>BAG ANTI-STATIC SHPG SP 019</td>\n",
       "      <td>BAG ANTI-STATIC SHPG SP 019 TÚI ĐÓNG GÓI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>019260049</td>\n",
       "      <td>BAG POLY \"X'</td>\n",
       "      <td>TÚI ĐÓNG GÓI</td>\n",
       "      <td>39239090</td>\n",
       "      <td>019</td>\n",
       "      <td>BAG POLY \"X' 019</td>\n",
       "      <td>BAG POLY \"X' 019 TÚI ĐÓNG GÓI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>019260051</td>\n",
       "      <td>ENVELOPE ANTI-STAT \" X \"</td>\n",
       "      <td>TÚI ĐÓNG GÓI</td>\n",
       "      <td>39239090</td>\n",
       "      <td>019</td>\n",
       "      <td>ENVELOPE ANTI-STAT \" X \" 019</td>\n",
       "      <td>ENVELOPE ANTI-STAT \" X \" 019 TÚI ĐÓNG GÓI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>019260072</td>\n",
       "      <td>BOX -/ X -/ X -/  PACK QSD</td>\n",
       "      <td>HỘP ĐÓNG GÓI (CARTON)</td>\n",
       "      <td>48191000</td>\n",
       "      <td>019</td>\n",
       "      <td>BOX -/ X -/ X -/  PACK QSD 019</td>\n",
       "      <td>BOX -/ X -/ X -/  PACK QSD 019 HỘP ĐÓNG GÓI (C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pn                        text              target_vi target_hs  \\\n",
       "0  010154002         SCREW  X WN WZ POZI                 ỐC VÍT  73181500   \n",
       "1  019260044     BAG ANTI-STATIC SHPG SP           TÚI ĐÓNG GÓI  39239090   \n",
       "2  019260049                BAG POLY \"X'           TÚI ĐÓNG GÓI  39239090   \n",
       "3  019260051    ENVELOPE ANTI-STAT \" X \"           TÚI ĐÓNG GÓI  39239090   \n",
       "4  019260072  BOX -/ X -/ X -/  PACK QSD  HỘP ĐÓNG GÓI (CARTON)  48191000   \n",
       "\n",
       "  pn_text                         text_vi  \\\n",
       "0     010         SCREW  X WN WZ POZI 010   \n",
       "1     019     BAG ANTI-STATIC SHPG SP 019   \n",
       "2     019                BAG POLY \"X' 019   \n",
       "3     019    ENVELOPE ANTI-STAT \" X \" 019   \n",
       "4     019  BOX -/ X -/ X -/  PACK QSD 019   \n",
       "\n",
       "                                             text_hs  \n",
       "0                     SCREW  X WN WZ POZI 010 ỐC VÍT  \n",
       "1           BAG ANTI-STATIC SHPG SP 019 TÚI ĐÓNG GÓI  \n",
       "2                      BAG POLY \"X' 019 TÚI ĐÓNG GÓI  \n",
       "3          ENVELOPE ANTI-STAT \" X \" 019 TÚI ĐÓNG GÓI  \n",
       "4  BOX -/ X -/ X -/  PACK QSD 019 HỘP ĐÓNG GÓI (C...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# OPTION 2 : read  file from github repository - worked\n",
    "url = 'https://github.com/khangvan/datasets/blob/master/dlhts_rev2.xlsx?raw=true'\n",
    "dfo = pd.read_excel(url,encoding=\"latin-1\")\n",
    "df=copy.copy(dfo)\n",
    "# Dataset is now stored in a Pandas Dataframe\n",
    "\n",
    "\n",
    "# CONVERT TO STRING\n",
    "dfo = df.apply(lambda x: x.astype(str) if x.name in ['PARTNUMBER', 'HTS CODE'] else x, axis=1)\n",
    "dfo.head()\n",
    "\n",
    "#---------------------------------DATA PREPROCESSING\n",
    "\n",
    "df=copy.copy(dfo)\n",
    "# drop na\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "# FORCE RULE 9len of Partnumber if shortage\n",
    "def zfill9(row,col_name='PARTNUMBER'):\n",
    "    r=str(row[col_name])\n",
    "    if len(r) <9:\n",
    "        r=r.zfill(9)\n",
    "    else:\n",
    "        r\n",
    "    return r\n",
    "df['PARTNUMBER']=df.apply(zfill9,axis=1)\n",
    "\n",
    "# add padlefft 0, 9; then get 3\n",
    "\n",
    "def zfill_custom(row,col_name='PARTNUMBER'):\n",
    "    myrow=str(row[col_name])\n",
    "    return myrow.zfill(9)[0:3]\n",
    "df['pn_text']=df.apply(zfill_custom,axis=1)\n",
    "\n",
    "# SHAPING data to have target and text\n",
    "import copy\n",
    "\n",
    "df_origin =  copy.copy(df)\n",
    "# df=df_origin[['DESCRIPTIONVI','DESCRIPTIONEN', 'pn_text']]\n",
    "# df.columns = [\"target\", \"text\", 'pn_text']\n",
    "\n",
    "# PREPROCESSING ENG DESCRIPTION <punctuation\n",
    "\n",
    "\n",
    "df.rename(columns={\n",
    "    \"DESCRIPTIONVI\":\"target_vi\"\n",
    "    ,\"DESCRIPTIONEN\":\"text\"\n",
    "    ,\"HTS CODE\": \"target_hs\"\n",
    "    ,\"PARTNUMBER\":\"pn\"\n",
    "}, inplace=True)\n",
    "\n",
    "import string\n",
    "\n",
    "def replace_punctuation_2space(row, col_name_need_remove='text'):\n",
    "  translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "  return row[col_name_need_remove].translate(translator)\n",
    "# df['text']=df.apply(replace_punctuation_2space,axis=1)\n",
    "\n",
    "df['text_vi']=df['text'].astype(str)+' ' +df['pn_text'].astype(str)\n",
    "df['text_hs']=df['text'].astype(str)+' ' +df['pn_text'].astype(str)+' '+df['target_vi'].astype(str)\n",
    "\n",
    "df['target_hs']=df['target_hs'].astype(str).replace('\\.0', '', regex=True)\n",
    "df['target_hs']=df['target_hs'].apply(lambda x: x[0:8])\n",
    "\n",
    "##--------------hscode change day cap dien\n",
    "#: 8544119000 đổi qua 85444922 rồi mà anh? Oct142019 10:52 AM\n",
    "df['target_hs']=df['target_hs'].apply(lambda x: x.replace(\"8544119000\",\"85444922\"))\n",
    "df['target_hs']=df['target_hs'].apply(lambda x: x.replace(\"85441190\",\"85444922\"))\n",
    "#test df[df['target_hs']=='85444922'].head(100) -- done\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T01:36:46.425929Z",
     "start_time": "2019-10-01T01:35:49.626873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn</th>\n",
       "      <th>text</th>\n",
       "      <th>target_vi</th>\n",
       "      <th>target_hs</th>\n",
       "      <th>pn_text</th>\n",
       "      <th>text_vi</th>\n",
       "      <th>text_hs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010154002</td>\n",
       "      <td>SCREW  X WN WZ POZI</td>\n",
       "      <td>ỐC VÍT</td>\n",
       "      <td>73181500</td>\n",
       "      <td>010</td>\n",
       "      <td>SCREW  X WN WZ POZI 010</td>\n",
       "      <td>SCREW  X WN WZ POZI 010 ỐC VÍT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>019260044</td>\n",
       "      <td>BAG ANTI-STATIC SHPG SP</td>\n",
       "      <td>TÚI ĐÓNG GÓI</td>\n",
       "      <td>39239090</td>\n",
       "      <td>019</td>\n",
       "      <td>BAG ANTI-STATIC SHPG SP 019</td>\n",
       "      <td>BAG ANTI-STATIC SHPG SP 019 TÚI ĐÓNG GÓI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>019260049</td>\n",
       "      <td>BAG POLY \"X'</td>\n",
       "      <td>TÚI ĐÓNG GÓI</td>\n",
       "      <td>39239090</td>\n",
       "      <td>019</td>\n",
       "      <td>BAG POLY \"X' 019</td>\n",
       "      <td>BAG POLY \"X' 019 TÚI ĐÓNG GÓI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>019260051</td>\n",
       "      <td>ENVELOPE ANTI-STAT \" X \"</td>\n",
       "      <td>TÚI ĐÓNG GÓI</td>\n",
       "      <td>39239090</td>\n",
       "      <td>019</td>\n",
       "      <td>ENVELOPE ANTI-STAT \" X \" 019</td>\n",
       "      <td>ENVELOPE ANTI-STAT \" X \" 019 TÚI ĐÓNG GÓI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>019260072</td>\n",
       "      <td>BOX -/ X -/ X -/  PACK QSD</td>\n",
       "      <td>HỘP ĐÓNG GÓI (CARTON)</td>\n",
       "      <td>48191000</td>\n",
       "      <td>019</td>\n",
       "      <td>BOX -/ X -/ X -/  PACK QSD 019</td>\n",
       "      <td>BOX -/ X -/ X -/  PACK QSD 019 HỘP ĐÓNG GÓI (C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pn                        text              target_vi target_hs  \\\n",
       "0  010154002         SCREW  X WN WZ POZI                 ỐC VÍT  73181500   \n",
       "1  019260044     BAG ANTI-STATIC SHPG SP           TÚI ĐÓNG GÓI  39239090   \n",
       "2  019260049                BAG POLY \"X'           TÚI ĐÓNG GÓI  39239090   \n",
       "3  019260051    ENVELOPE ANTI-STAT \" X \"           TÚI ĐÓNG GÓI  39239090   \n",
       "4  019260072  BOX -/ X -/ X -/  PACK QSD  HỘP ĐÓNG GÓI (CARTON)  48191000   \n",
       "\n",
       "  pn_text                         text_vi  \\\n",
       "0     010         SCREW  X WN WZ POZI 010   \n",
       "1     019     BAG ANTI-STATIC SHPG SP 019   \n",
       "2     019                BAG POLY \"X' 019   \n",
       "3     019    ENVELOPE ANTI-STAT \" X \" 019   \n",
       "4     019  BOX -/ X -/ X -/  PACK QSD 019   \n",
       "\n",
       "                                             text_hs  \n",
       "0                     SCREW  X WN WZ POZI 010 ỐC VÍT  \n",
       "1           BAG ANTI-STATIC SHPG SP 019 TÚI ĐÓNG GÓI  \n",
       "2                      BAG POLY \"X' 019 TÚI ĐÓNG GÓI  \n",
       "3          ENVELOPE ANTI-STAT \" X \" 019 TÚI ĐÓNG GÓI  \n",
       "4  BOX -/ X -/ X -/  PACK QSD 019 HỘP ĐÓNG GÓI (C...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "# df[\"target\"]=MultiColumnLabelEncoder(columns = ['target']).fit_transform(df)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T01:36:46.477689Z",
     "start_time": "2019-10-01T01:36:06.954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vi target_vi VI_CLF.model VI_CLF_report.df\n",
      "MÁY ĐỌC MÃ VẠCH                  0.200573\n",
      "BẢNG MẠCH IN ĐIỆN TỬ             0.147615\n",
      "MẠCH ĐIỆN TỬ TÍCH HỢP            0.048795\n",
      "ĐIỆN TRỞ                         0.045178\n",
      "MẠCH IN                          0.038832\n",
      "DÂY CÁP ĐIỆN                     0.034054\n",
      "TỤ ĐIỆN                          0.033508\n",
      "PHỤ KIỆN BẢNG MẠCH IN ĐIỆN TỬ    0.027776\n",
      "SÁCH HƯỚNG DẪN                   0.026343\n",
      "ĐẦU NỐI                          0.024432\n",
      "Name: target_vi, dtype: float64\n",
      "X shape (14653,), type <class 'pandas.core.series.Series'>, len 14653\n",
      "y shape (14653,), type <class 'pandas.core.series.Series'>, len 14653\n",
      "X_train shape (9817,), type <class 'pandas.core.series.Series'>, len 9817\n",
      "y_train shape (9817,), type <class 'pandas.core.series.Series'>, len 9817\n",
      "acc 85.67%\n",
      "hs target_hs HS_CLF.model HS_CLF_report.df\n",
      "84719010    0.200437\n",
      "84733090    0.180304\n",
      "84733010    0.148297\n",
      "85423100    0.050160\n",
      "85332100    0.045178\n",
      "85340030    0.037740\n",
      "85444922    0.034054\n",
      "85322400    0.033645\n",
      "49019990    0.032144\n",
      "39269099    0.031598\n",
      "Name: target_hs, dtype: float64\n",
      "X shape (14653,), type <class 'pandas.core.series.Series'>, len 14653\n",
      "y shape (14653,), type <class 'pandas.core.series.Series'>, len 14653\n",
      "X_train shape (9817,), type <class 'pandas.core.series.Series'>, len 9817\n",
      "y_train shape (9817,), type <class 'pandas.core.series.Series'>, len 9817\n",
      "acc 95.78%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config=[\n",
    "    (\"vi\",'text_vi','target_vi','VI_CLF.model', 'VI_CLF_report.df' ),\n",
    "    (\"hs\",'text_hs', 'target_hs', 'HS_CLF.model', 'HS_CLF_report.df' ),\n",
    "]\n",
    "mydf=pd.DataFrame.from_records(config,columns=['idx','text','target','model_name','report_name'])\n",
    "mydf\n",
    "for index, _ in mydf.iterrows():\n",
    "    my_code=_.idx\n",
    "    my_text=_.text\n",
    "    my_target=_.target\n",
    "    my_model_name=_.model_name\n",
    "    my_report_name=_.report_name\n",
    "    print (my_code, my_target, my_model_name, my_report_name)\n",
    "\n",
    "    print((df[my_target].value_counts()/len(df.index)).head(10))\n",
    "    X=df[my_text]\n",
    "    y=df[my_target]\n",
    "    print('X shape %s, type %s, len %s' % (X.shape,type(X),len(X)))\n",
    "    print('y shape %s, type %s, len %s' % (y.shape,type(y),len(y)))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,y, random_state=0, test_size=0.33\n",
    "    )\n",
    "\n",
    "    print('X_train shape %s, type %s, len %s' % (X_train.shape,type(X_train),len(X_train)))\n",
    "    print('y_train shape %s, type %s, len %s' % (y_train.shape,type(y_train),len(y_train)))\n",
    "\n",
    "    def df_vectorize(X_train_):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "        #------------------Vectorize TRAIN---------------------------\n",
    "        ## Build Bag-Of-Words on train phrases\n",
    "        cv = CountVectorizer()\n",
    "        cv_X_train = cv.fit_transform(X_train)\n",
    "        # print(cv_X_train.shape)\n",
    "\n",
    "        # build TFIDF features on train reviews\n",
    "        # tv = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2),       sublinear_tf=True)\n",
    "        tv = TfidfVectorizer()\n",
    "        tv_X_train = tv.fit_transform(X_train)\n",
    "        # print(tv_X_train.shape)\n",
    "        return cv_X_train,tv_X_train\n",
    "    cv_X_train,tv_X_train = df_vectorize(X_train)\n",
    "    #------------------Vectorize TEST---------------------------\n",
    "    # transform test reviews into features\n",
    "    # cv_X_test = cv.transform(X_test)\n",
    "    # tv_X_test = tv.transform(X_test)\n",
    "    cv_X_test,tv_X_test = df_vectorize(X_test)\n",
    "\n",
    "\n",
    "    # print(cv_X_test.shape)\n",
    "    # print(tv_X_test.shape)\n",
    "\n",
    "    # We create the preprocessing pipelines for both numeric and categorical data.\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    # from sklearn.linear_model import SGDClassifier\n",
    "    text_clf_pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB(alpha=1e-3)),\n",
    "    ])\n",
    "\n",
    "    text_clf_pipeline.fit(X_train, y_train)  \n",
    "\n",
    "    y_predicted = text_clf_pipeline.predict(X_test)\n",
    "    print(\"acc %.2f%%\" % (np.mean(y_predicted == y_test)*100))\n",
    "\n",
    "\n",
    "    # # save the model to disk\n",
    "    import pickle\n",
    "    filename = my_model_name #'HTSCODE_VI.sav'\n",
    "    pickle.dump(text_clf_pipeline, open(filename, 'wb')) # disable to prevent kill my model\n",
    "\n",
    "    \n",
    "    from sklearn import metrics\n",
    "\n",
    "    clsf_report = pd.DataFrame(metrics.classification_report(y_test, y_predicted, output_dict=True)).transpose()\n",
    "    clsf_report.sort_values(by=\"f1-score\", ascending =False, inplace=True)\n",
    "    \n",
    "    #save \n",
    "    pickle.dump(clsf_report, open(my_report_name, 'wb')) # disable to prevent kill my model\n",
    "    clsf_report.to_excel(my_report_name+\".xlsx\",engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI SELECTIVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "\n",
    "def run_selective():\n",
    "\n",
    "    clf1=MultinomialNB(alpha=1e-3)\n",
    "    clf2= SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=50, tol=None)\n",
    "    clf3=BaggingClassifier( DecisionTreeClassifier(random_state=42), n_estimators=50,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "    adaboost=AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "        algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "\n",
    "\n",
    "    gbrt=GradientBoostingClassifier(\n",
    "        max_depth=2, n_estimators=3, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    clf_svc=SVC(gamma='scale',random_state=0)\n",
    "\n",
    "    \n",
    "    config=[\n",
    "    (\"Vietnamese\",'text_vi','target_vi','VI_CLF.model', 'VI_CLF_report.df',clf1 ),\n",
    "    (\"HTSCode\",'text_hs', 'target_hs', 'HS_CLF.model', 'HS_CLF_report.df',clf1 ),\n",
    "    (\"Vietnamese\",'text_vi','target_vi','VI_CLF.model', 'VI_CLF_report.df',clf_svc ),\n",
    "    (\"HTSCode\",'text_hs', 'target_hs', 'HS_CLF.model', 'HS_CLF_report.df',clf_svc ),    \n",
    "\n",
    "#     (\"Vietnamese\",'text_vi','target_vi','VI_CLF.model', 'VI_CLF_report.df',clf2 ),\n",
    "#     (\"HTSCode\",'text_hs', 'target_hs', 'HS_CLF.model', 'HS_CLF_report.df',clf2 ),\n",
    "#     (\"Vietnamese\",'text_vi','target_vi','VI_CLF.model', 'VI_CLF_report.df',clf3 ),\n",
    "#     (\"HTSCode\",'text_hs', 'target_hs', 'HS_CLF.model', 'HS_CLF_report.df',clf3 ),\n",
    "#     (\"Vietnamese\",'text_vi','target_vi','VI_CLF.model', 'VI_CLF_report.df',adaboost ),\n",
    "#     (\"HTSCode\",'text_hs', 'target_hs', 'HS_CLF.model', 'HS_CLF_report.df',adaboost ),\n",
    "#     (\"Vietnamese\",'text_vi','target_vi','VI_CLF.model', 'VI_CLF_report.df',gbrt ),\n",
    "#     (\"HTSCode\",'text_hs', 'target_hs', 'HS_CLF.model', 'HS_CLF_report.df',gbrt ),\n",
    "    ]\n",
    "    mydf=pd.DataFrame.from_records(config,columns=['idx','text','target','model_name','report_name','algorithm'])\n",
    "#     mydf\n",
    "    i=1\n",
    "    sum_df=[]\n",
    "    for index, _ in mydf.iterrows():\n",
    "        my_code=_.idx\n",
    "        my_text=_.text\n",
    "        my_target=_.target\n",
    "        my_model_name=_.model_name\n",
    "        my_report_name=_.report_name\n",
    "        my_algorithm=_.algorithm\n",
    "        feature_target=(my_code, my_text,my_target, my_model_name, my_report_name)\n",
    "        print (str(i)+\"-\" ,feature_target, str(my_algorithm))\n",
    "\n",
    "\n",
    "        X=df[my_text]\n",
    "        y=df[my_target]\n",
    "#         print('X shape %s, type %s, len %s' % (X.shape,type(X),len(X)))\n",
    "#         print('y shape %s, type %s, len %s' % (y.shape,type(y),len(y)))\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,y, random_state=0, test_size=0.33\n",
    "        )\n",
    "\n",
    "#         print('X_train shape %s, type %s, len %s' % (X_train.shape,type(X_train),len(X_train)))\n",
    "#         print('y_train shape %s, type %s, len %s' % (y_train.shape,type(y_train),len(y_train)))\n",
    "\n",
    "       \n",
    "        # from sklearn.linear_model import SGDClassifier\n",
    "        text_clf_pipeline = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf',my_algorithm ),\n",
    "        ])\n",
    "\n",
    "        text_clf_pipeline.fit(X_train, y_train)  \n",
    "\n",
    "        y_predicted = text_clf_pipeline.predict(X_test)\n",
    "        acc=(np.mean(y_predicted == y_test)*100)\n",
    "        print(\"=> Accuraccy %.2f%%\" % acc)\n",
    "        i+=1\n",
    "        row=()\n",
    "        sum_df.append((str(my_algorithm),feature_target,acc))\n",
    "    oi_df=pd.DataFrame.from_records(sum_df,columns=['Algorithm','feature_target','Accuracy%'])\n",
    "    oi_df.reset_index(drop=True,inplace=True)\n",
    "    return oi_df\n",
    "run_selective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST IN ACTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 95.78%\n",
      "'ADDENDUM,REG,MGL3400/3500' => 49011000\n",
      "'ASSY MODULE FIREFLY DE2101-DL GS' => 84733090\n",
      "'OPTICAL CHAMBER SUBASSY PUL2 STD MIC' => 39269059\n",
      "'LOADCELL,30KG,SHEKEL,C72D' => 84733090\n",
      "'LOCKING SYST BASE ASSY LIGHT, CRADLE MIC' => 39269059\n",
      "'FAB, FE4629, CUMULUS ILLUMINATION 100' => 85340030\n",
      "'VF - 233 SCREW M1,4X0,3 L=4 TORX T3' => 73181590\n",
      "'CVL-1057 RS232 OUTPUT CABLE TC1200' => 85444922\n",
      "'IC STR91XF 16/32-BIT FLASH MCU LQFP128' => 85423100\n",
      "'CVL-1120 OUTPUT CABLE TC1200 SB4507' => 85444922\n",
      "'cable' => 85444922\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'HS_CLF.model'\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "predicted = loaded_model.predict(X_test)\n",
    "print(\"acc %.2f%%\" % (np.mean(predicted == y_test)*100))\n",
    "\n",
    "data = np.array([\n",
    "    'ADDENDUM,REG,MGL3400/3500',\n",
    "    'ASSY MODULE FIREFLY DE2101-DL GS',\n",
    "    'OPTICAL CHAMBER SUBASSY PUL2 STD MIC',\n",
    "    'LOADCELL,30KG,SHEKEL,C72D',\n",
    "    'LOCKING SYST BASE ASSY LIGHT, CRADLE MIC',\n",
    "    'FAB, FE4629, CUMULUS ILLUMINATION 100',\n",
    "    'VF - 233 SCREW M1,4X0,3 L=4 TORX T3', \n",
    "    'CVL-1057 RS232 OUTPUT CABLE TC1200',\n",
    "    'IC STR91XF 16/32-BIT FLASH MCU LQFP128',\n",
    "  'CVL-1120 OUTPUT CABLE TC1200 SB4507',\n",
    "    'cable'\n",
    "])\n",
    "data = pd.Series(data)\n",
    "\n",
    "predicted = loaded_model.predict(data)\n",
    "# verify actual to see if \n",
    "for doc, category in zip(data, predicted):\n",
    "    print('%r => %s' % (doc, category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(alpha=1e-3)),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "print(\"acc %.2f%%\" % (np.mean(predicted == y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=100, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train, y_train)  \n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(\"acc %.2f%%\" % (np.mean(predicted == y_test)*100))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# ENSEMBLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "bag_clf=BaggingClassifier( DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "\n",
    "bag_clf=Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', BaggingClassifier( DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred=bag_clf.predict(X_test)\n",
    "print(\"Accuracy BaggingClassifier_CV %.2f%%\" % (np.mean(y_pred == y_test)*100))\n",
    "#-------------------\n",
    "# bag_clf_2=BaggingClassifier(\n",
    "#     DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "#     max_samples=100, bootstrap=True, n_jobs=-1, random_state=42\n",
    "# )\n",
    "\n",
    "# bag_clf_2.fit(tv_X_train, y_train)\n",
    "# y_pred=bag_clf_2.predict(tv_X_test)\n",
    "# print(\"Accuracy BaggingClassifier_TV %.2f%%\" % (np.mean(y_pred == y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboosting- chậm hơn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "ada_clf=Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "        algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "    ),\n",
    "])\n",
    "\n",
    "# ada_clf=AdaBoostClassifier(\n",
    "# DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "#     algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42\n",
    "# )\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred=ada_clf.predict(X_test)\n",
    "print(\"Accuracy AdaBoostClassifier %.2f%%\" % (np.mean(y_pred == y_test)*100))\n",
    "\n",
    "\n",
    "# ada_clf.fit(tv_X_train, y_train)\n",
    "# y_pred=ada_clf.predict(tv_X_test)\n",
    "# print(\"Accuracy AdaBoostClassifier %.2f%%\" % (np.mean(y_pred == y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiant Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "#hooi quy\n",
    "# gbrt=GradientBoostingRegressor(\n",
    "#     max_depth=2, n_estimators=3, learning_rate=1, random_state=42\n",
    "# )\n",
    "gbrt=GradientBoostingClassifier(\n",
    "    max_depth=2, n_estimators=3, learning_rate=1, random_state=42\n",
    ")\n",
    "\n",
    "gbrt.fit(cv_X_train, y_train)\n",
    "y_pred=gbrt.predict(cv_X_test)\n",
    "print(\"Accuracy Gradiant Boosting CV %.2f%%\" % (np.mean(y_pred == y_test)*100))\n",
    "\n",
    "\n",
    "gbrt.fit(tv_X_train, y_train)\n",
    "y_pred=gbrt.predict(tv_X_test)\n",
    "print(\"Accuracy Gradiant Boosting TV %.2f%%\" % (np.mean(y_pred == y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPLOY METHOD IN PRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"'JOYA TOUCH QUICK START GUIDE TR         822' => SÁCH HƯỚNG DẪN\" => 49019990\n",
      "\"'LABEL COOP SWEDEN                       163' => NHÃN (NHỰA)\" => 39191090\n",
      "\"'LENSES HOLDER REWORKED                  131' => VỎ GIỮ THẤU KÍNH (HỢP KIM KẼM)\" => 79012000\n",
      "vi ['SÁCH HƯỚNG DẪN' 'NHÃN (NHỰA)' 'VỎ GIỮ THẤU KÍNH (HỢP KIM KẼM)']\n",
      "hs ['49019990' '39191090' '79012000']\n",
      "eng ['JOYA TOUCH QUICK START GUIDE TR         822', 'LABEL COOP SWEDEN                       163', 'LENSES HOLDER REWORKED                  131']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_input</th>\n",
       "      <th>en</th>\n",
       "      <th>vi</th>\n",
       "      <th>hs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>822002101</td>\n",
       "      <td>JOYA TOUCH QUICK START GUIDE TR         822</td>\n",
       "      <td>SÁCH HƯỚNG DẪN</td>\n",
       "      <td>49019990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163333400</td>\n",
       "      <td>LABEL COOP SWEDEN                       163</td>\n",
       "      <td>NHÃN (NHỰA)</td>\n",
       "      <td>39191090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131129100</td>\n",
       "      <td>LENSES HOLDER REWORKED                  131</td>\n",
       "      <td>VỎ GIỮ THẤU KÍNH (HỢP KIM KẼM)</td>\n",
       "      <td>79012000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  material_input                                           en  \\\n",
       "0      822002101  JOYA TOUCH QUICK START GUIDE TR         822   \n",
       "1      163333400  LABEL COOP SWEDEN                       163   \n",
       "2      131129100  LENSES HOLDER REWORKED                  131   \n",
       "\n",
       "                               vi        hs  \n",
       "0                  SÁCH HƯỚNG DẪN  49019990  \n",
       "1                     NHÃN (NHỰA)  39191090  \n",
       "2  VỎ GIỮ THẤU KÍNH (HỢP KIM KẼM)  79012000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data = np.array([\n",
    "    'ADDENDUM,REG,MGL3400/3500',\n",
    "    'ASSY MODULE FIREFLY DE2101-DL GS',\n",
    "    'OPTICAL CHAMBER SUBASSY PUL2 STD MIC',\n",
    "    'LOADCELL,30KG,SHEKEL,C72D',\n",
    "    'LOCKING SYST BASE ASSY LIGHT, CRADLE MIC',\n",
    "    'FAB, FE4629, CUMULUS ILLUMINATION',\n",
    "    'VF - 233 SCREW M1,4X0,3 L=4 TORX T3', \n",
    "    'CVL-1057 RS232 OUTPUT CABLE TC1200',\n",
    "    'IC STR91XF 16/32-BIT FLASH MCU LQFP128',\n",
    "  'CVL-1120 OUTPUT CABLE TC1200 SB4507'\n",
    "])\n",
    "\n",
    "def goVector(X_test):\n",
    "    X_new_counts = count_vect.transform(X_test)\n",
    "    X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "    return X_new_tfidf\n",
    "\n",
    "def predict_from_description(model_name, data_input):\n",
    "#     \"HTSCODE_VI.sav\",\"HTSCODE_HS.sav\"\n",
    "    data = pd.Series(data_input)\n",
    "        \n",
    "    loaded_model = pickle.load(open(model_name, 'rb'))\n",
    "    predicted = loaded_model.predict((data))\n",
    "\n",
    "    # predicted = text_clf.predict(X_test)\n",
    "    # print(\"acc %.2f%%\" % (np.mean(predicted == y_test)*100))\n",
    "\n",
    "    for doc, category in zip(data, predicted):\n",
    "        print('%r => %s' % (doc, category))\n",
    "    return predicted\n",
    "        \n",
    "##-predict all\n",
    "\n",
    "def predict_data_vi_hs(data_input=data):\n",
    "    data = pd.Series(data_input)\n",
    "\n",
    "#          -----------------\n",
    "#version 1\n",
    "#     list_model=[\"VI_CLF.model\",\"HS_CLF.model\"]\n",
    "#     list_predict=[]\n",
    "#     for item in range(len(list_model)):\n",
    "# #         print(list_model[item])\n",
    "#         model_name=list_model[item]\n",
    "\n",
    "#         loaded_model = pickle.load(open(model_name, 'rb'))\n",
    "#         predicted = loaded_model.predict((data))\n",
    "#         list_predict.append(predicted)\n",
    "\n",
    "#          -----------------\n",
    "#version 2\n",
    "\n",
    "    list_model=[\"VI_CLF.model\",\"HS_CLF.model\"]\n",
    "    list_predict=[]\n",
    "#         for item in range(len(list_model)):\n",
    "#         print(list_model[item])\n",
    "#             model_name=list_model[item]\n",
    "\n",
    "    loaded_model = pickle.load(open(list_model[0], 'rb'))\n",
    "    predicted = loaded_model.predict((data))\n",
    "    list_predict.append(predicted)\n",
    "    loaded_model = pickle.load(open(list_model[1], 'rb'))\n",
    "\n",
    "    #khangvan\n",
    "    newdf= pd.DataFrame(dict(s1 = data, s2 = predicted)).reset_index()\n",
    "   \n",
    "    newdf[\"newdata\"]=newdf['s1']+' '+newdf['s2']\n",
    "    newdata =newdf[\"newdata\"]\n",
    "    \n",
    "#     for doc, category in zip(data,vi_df ):\n",
    "#         newdf4hs=data+\" \"+vi_df\n",
    "#         print(newdf4hs)\n",
    "#         newdata.append(newdf4hs)\n",
    "    predicted = loaded_model.predict((newdata))\n",
    "    list_predict.append(predicted)\n",
    "\n",
    "            \n",
    "#         ----------    \n",
    "\n",
    "\n",
    "    main=[]\n",
    "    for doc, category in zip(data, list_predict[0]):\n",
    "#         print('%r => %s' % (doc, category))\n",
    "        v='%r => %s' % (doc, category)\n",
    "#         print(type(v))\n",
    "        main.append('%r => %s' % (doc, category))\n",
    "    for doc, category in zip(main, list_predict[1]):\n",
    "        print('%r => %s' % ((doc), category))\n",
    "# predict_data_now('HTSCODE_VI.sav',data)\n",
    "# predict_data_now('HTSCODE_HS.sav',data)\n",
    "    vi=list_predict[0]\n",
    "    hs=list_predict[1]\n",
    "    en= data_input\n",
    "    final_df= pd.DataFrame(vi,columns=[\"vi\"])\n",
    "    final_df['hs']=hs\n",
    "    final_df['en']=en\n",
    "    final_df['input_data']=data\n",
    "    cols=['input_data','en', 'vi','hs']\n",
    "    return check_score_df(final_df[cols]) #vi, hs, en\n",
    "\n",
    "def goVector(actual_data):\n",
    "    tv = TfidfVectorizer()\n",
    "    tv_X_train = tv.fit_transform(actual_data)\n",
    "    return tv_X_train\n",
    "\n",
    "def predict_data_vi_hs_from_pn(material):\n",
    "    material = pd.Series(material)\n",
    "    data_input=saplinkinfo_multi(material) # return list description\n",
    "#     print(data_input)\n",
    "\n",
    "    data = pd.Series(data_input)\n",
    "    list_model=[\"VI_CLF.model\",\"HS_CLF.model\"]\n",
    "    list_predict=[]\n",
    "    for item in range(len(list_model)):\n",
    "#         print(list_model[item])\n",
    "        model_name=list_model[item]\n",
    "    \n",
    "        loaded_model = pickle.load(open(model_name, 'rb'))\n",
    "        predicted = loaded_model.predict((data))\n",
    "        list_predict.append(predicted)\n",
    "    main=[]\n",
    "    # Vi\n",
    "    for doc, category in zip(data, list_predict[0]):\n",
    "#         print('%r => %s' % (doc, category))\n",
    "        v='%r => %s' % (doc, category)\n",
    "#         print(type(v))\n",
    "        main.append('%r => %s' % (doc, category))\n",
    "    #HS\n",
    "    for doc, category in zip(main, list_predict[1]):\n",
    "        print('%r => %s' % (doc, category))\n",
    "    vi=list_predict[0]\n",
    "    hs=list_predict[1]\n",
    "    en= data_input\n",
    "    \n",
    "    print('vi',vi)\n",
    "    print('hs',hs)\n",
    "    print('eng',en)\n",
    "    \n",
    "    final_df= pd.DataFrame(vi,columns=[\"vi\"])\n",
    "    final_df['hs']=hs\n",
    "    final_df['en']=en\n",
    "    final_df['material_input']=material\n",
    "    cols=['material_input','en', 'vi','hs']\n",
    "#     return check_score_df(final_df[cols]) #vi, hs, en\n",
    "    return (final_df[cols]) #vi, hs, en\n",
    "\n",
    "\n",
    "def saplinkinfo(material='770112003'):\n",
    "    import xml.etree.ElementTree as ET\n",
    "    from urllib.request import urlopen\n",
    "    from xml.etree.ElementTree import parse\n",
    "    import time \n",
    "    import urllib.parse\n",
    "    start=time.time()\n",
    "#     material='770112003'\n",
    "    # tree = ET.parse('saplink.xml')\n",
    "    tag=fr'''\n",
    "    <Z_DMS_MATERIAL_INFO>\n",
    "    <LANG>E</LANG>\n",
    "    <WERKS></WERKS>\n",
    "    <VALIDON>03/23/2015</VALIDON>\n",
    "    <MATNR>{material}</MATNR>\n",
    "    </Z_DMS_MATERIAL_INFO>\n",
    "    '''\n",
    "    encodetag=urllib.parse.quote_plus(tag)\n",
    "\n",
    "    query='http://home/saplink/PRD/default.asp?XDoc='\n",
    "\n",
    "    url =query+encodetag\n",
    "#     print(url)\n",
    "\n",
    "    var_url = urlopen(url)\n",
    "    tree = parse(var_url)\n",
    "\n",
    "    # tree = ET.parse(url)\n",
    "    root = tree.getroot()\n",
    "    root.tag\n",
    "    # for child in root:\n",
    "    #     print(child.tag, child.attrib)\n",
    "\n",
    "    # [elem.tag for elem in root.iter()]\n",
    "    list_des=[]\n",
    "    material_description=\"\"\n",
    "    for description in root.iter('DESCRIPTION'):\n",
    "        material_description=description.text+ material[0:3]\n",
    "#         print(description.text)\n",
    "        list_des.append(material_description)\n",
    "#     print(\"run in seconds: %s\" % str(time.time()-start))\n",
    "    return list_des\n",
    "\n",
    "saplinkinfo('294100501')\n",
    "## work now<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "def saplinkinfo_multi(material):\n",
    "    import xml.etree.ElementTree as ET\n",
    "    from urllib.request import urlopen\n",
    "    from xml.etree.ElementTree import parse\n",
    "    import time \n",
    "    import urllib.parse\n",
    "    import asyncio\n",
    "    start=time.time()\n",
    "#     material='770112003'\n",
    "    # tree = ET.parse('saplink.xml')\n",
    "    list_name=[]\n",
    "    for item in range(len(material)):\n",
    "#         print(material[item])\n",
    "        list_name.append(saplinkinfo(material[item])[0])\n",
    "#     print(list_name)\n",
    "    return list_name\n",
    "# saplinkinfo_multi(['GD4130-BK','287021700'])\n",
    "\n",
    "## work now<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "# @staticmethod\n",
    "def check_score_df(mytest):\n",
    "    import pickle\n",
    "    mydf=copy.copy(mytest)\n",
    "    vi_df = pickle.load(open('VI_CLF_report.df', 'rb'))\n",
    "    hs_df = pickle.load(open('HS_CLF_report.df', 'rb'))\n",
    "    vi_df[\"vi\"]=vi_df.index\n",
    "    hs_df[\"hs\"]=hs_df.index\n",
    "    mydf =mydf.merge(vi_df, left_on='vi', right_on='vi')\n",
    "    # print(mydf.columns)\n",
    "    mydf.drop(columns=['precision','recall','support'],inplace=True)\n",
    "    mydf.rename(columns={\"f1-score\": \"vi_f1_score\"}, inplace=True)\n",
    "\n",
    "    mydf =mydf.merge(hs_df, left_on='hs', right_on='hs')\n",
    "    mydf.drop(columns=['precision','recall','support'],inplace=True)\n",
    "    mydf.rename(columns={\"f1-score\": \"hs_f1_score\"}, inplace=True)\n",
    "\n",
    "    def mynote(row):\n",
    "        vi_rate=row['vi_f1_score']\n",
    "        hs_rate=row['hs_f1_score']\n",
    "        cmt1= 'vi check' if vi_rate <0.5 else ''\n",
    "        cmt2= 'hs check' if hs_rate <0.5 else ''\n",
    "        return cmt1+ ' ' +cmt2\n",
    "    mydf['mynote']=mydf.apply(mynote, axis=1)\n",
    "\n",
    "    return mydf\n",
    "\n",
    "# predict_data_vi_hs()\n",
    "\n",
    "data=[\n",
    "#    '131118061',\n",
    "# '292004761',\n",
    "'822002101', \n",
    "    '163333400',\n",
    "    '131129100'\n",
    "]\n",
    "predict_data_vi_hs_from_pn(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LENSES HOLDER REWORKED                  131']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saplinkinfo('131129100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY CLASS in OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-7772c4d5346f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;31m# dl.pn_new_dichviet_hscode()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;31m# dl.check_bieuthue(84719010)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpn_dichviet_hscode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m \u001b[1;31m# dl.save_temp_server(dl.pn_dichviet_hscode())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;31m# dl.update_server_master()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-87-7772c4d5346f>\u001b[0m in \u001b[0;36mpn_dichviet_hscode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpn_dichviet_hscode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m#         print('pn',self.pn_list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mmydata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaplinkinfo_multi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpn_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m#         print('eng from my data', mydata)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-87-7772c4d5346f>\u001b[0m in \u001b[0;36msaplinkinfo_multi\u001b[1;34m(material)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[0meng_item\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msaplinkinfo_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaterial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;31m#             print(eng_item)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m             \u001b[0mlist_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meng_item\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[0meng_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0meng_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sqlalchemy\n",
    "import pyodbc\n",
    "    \n",
    "\n",
    "class datalogic_hscode_vi:\n",
    "\n",
    "    def __int__(self, data):\n",
    "        _=datalogic_hscode_vi() # set obj inside to quick call sstatic method\n",
    "        import_all_lib()\n",
    "        self.data=data\n",
    "        self.finaldata=[]\n",
    "    # attribute ===================================================================\n",
    "    \n",
    "    pn_list=[]\n",
    "    des_list=[]\n",
    "    des_list_sample=([\n",
    "    'ADDENDUM,REG,MGL3400/3500',\n",
    "    'ASSY MODULE FIREFLY DE2101-DL GS',\n",
    "    'OPTICAL CHAMBER SUBASSY PUL2 STD MIC',\n",
    "    'LOADCELL,30KG,SHEKEL,C72D',\n",
    "    'LOCKING SYST BASE ASSY LIGHT, CRADLE MIC',\n",
    "    'FAB, FE4629, CUMULUS ILLUMINATION 100',\n",
    "    'VF - 233 SCREW M1,4X0,3 L=4 TORX T3', \n",
    "    'CVL-1057 RS232 OUTPUT CABLE TC1200',\n",
    "    'IC STR91XF 16/32-BIT FLASH MCU LQFP128',\n",
    "      'CVL-1120 OUTPUT CABLE TC1200 SB4507'\n",
    "    ])\n",
    "    \n",
    "    pn_list_sample=([\n",
    "    'ADDENDUM,REG,MGL3400/3500',\n",
    "    'ASSY MODULE FIREFLY DE2101-DL GS',\n",
    "    'OPTICAL CHAMBER SUBASSY PUL2 STD MIC',\n",
    "    'LOADCELL,30KG,SHEKEL,C72D',\n",
    "    'LOCKING SYST BASE ASSY LIGHT, CRADLE MIC',\n",
    "    'FAB, FE4629, CUMULUS ILLUMINATION 100',\n",
    "    'VF - 233 SCREW M1,4X0,3 L=4 TORX T3', \n",
    "    'CVL-1057 RS232 OUTPUT CABLE TC1200',\n",
    "    'IC STR91XF 16/32-BIT FLASH MCU LQFP128',\n",
    "      'CVL-1120 OUTPUT CABLE TC1200 SB4507'\n",
    "    ])\n",
    "    finaldata=[]\n",
    "    # self/instance method ===================================================================\n",
    "    def import_all_lib(self):\n",
    "        print('lib import done')\n",
    "        \n",
    "    def check_len_df(self):\n",
    "        print(\"pn:\" , len(self.pn_list))\n",
    "        print(\"pn:\" , len(self.des_list))\n",
    "    \n",
    "    \n",
    "    def set_data_pn(self,data):\n",
    "        self.pn_list=data\n",
    "    def set_data_des(self,data):\n",
    "        self.des_list=data\n",
    "    \n",
    "    def pn_dichviet(self):\n",
    "        pass\n",
    "        \n",
    "    def pn_hscode(self):\n",
    "        pass\n",
    "        \n",
    "    def pn_dichviet_hscode(self):\n",
    "#         print('pn',self.pn_list)\n",
    "        mydata=self.saplinkinfo_multi(self.pn_list)\n",
    "        \n",
    "#         print('eng from my data', mydata)\n",
    "        return self.predict_data_vi_hs_from_pn(self.pn_list,mydata)\n",
    "\n",
    "    def des_dichviet_hscode(self):\n",
    "#         print('pn',self.pn_list)\n",
    "        mydata=self.des_list\n",
    "        \n",
    "#         print('eng from my data', mydata)\n",
    "        return self.predict_data_vi_hs_from_pn(self.des_list,mydata)\n",
    "\n",
    "    def des_dichviet(self):\n",
    "#         self.check_len_df()\n",
    "        self.predict_from_description('vi',self.des_list)\n",
    "        \n",
    "    def des_hscode(self):\n",
    "#         self.check_len_df()\n",
    "        self.predict_from_description('hs',self.des_list)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    # class/cls method===================================================================\n",
    "\n",
    "    \n",
    "    # statis method ===================================================================\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_from_description(target, datainput):\n",
    "        filename = \"VI_CLF.model\" if (target==\"\" or target==\"vi\") else \"HS_CLF.model\" # defalut VI\n",
    "#         print(filename)\n",
    "        data = pd.Series(datainput)\n",
    "\n",
    "        loaded_model = pickle.load(open(filename, 'rb'))\n",
    "        predicted = loaded_model.predict((data))\n",
    "\n",
    "        for doc, category in zip(data, predicted):\n",
    "            print('%r => %s' % (doc, category))\n",
    "        return predicted\n",
    "    @staticmethod\n",
    "    def goVector(X_text): # no need use\n",
    "        tv = TfidfVectorizer()\n",
    "        tv_X_train = tv.fit_transform(X_text)\n",
    "        return tv_X_train\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_data_vi_hs_from_pn(datainput, eng_list):\n",
    "#         print('len là ',len(datainput))\n",
    "#         print(self.data)\n",
    "#         print(type(self.data)) # class dataFrame\n",
    "        \n",
    "#         material = (self.data.values)\n",
    "        material = (datainput)\n",
    "#         print('material',(material))\n",
    "#         eng_list=saplinkinfo_multi(material) # return list description\n",
    "    #     print(data_input)\n",
    "    \n",
    "        data = (eng_list)\n",
    "#         print('data pn là:', material)\n",
    "#         print('eng_list saplink là: ', eng_list)\n",
    "#          -----------------\n",
    "#version 1\n",
    "#     list_model=[\"VI_CLF.model\",\"HS_CLF.model\"]\n",
    "#     list_predict=[]\n",
    "#     for item in range(len(list_model)):\n",
    "# #         print(list_model[item])\n",
    "#         model_name=list_model[item]\n",
    "\n",
    "#         loaded_model = pickle.load(open(model_name, 'rb'))\n",
    "#         predicted = loaded_model.predict((data))\n",
    "#         list_predict.append(predicted)\n",
    "\n",
    "#          -----------------\n",
    "#version 2\n",
    "\n",
    "        list_model=[\"VI_CLF.model\",\"HS_CLF.model\"]\n",
    "        list_predict=[]\n",
    "    #         for item in range(len(list_model)):\n",
    "    #         print(list_model[item])\n",
    "    #             model_name=list_model[item]\n",
    "\n",
    "        loaded_model = pickle.load(open(list_model[0], 'rb'))\n",
    "        predicted = loaded_model.predict(data)\n",
    "        list_predict.append(predicted)\n",
    "        loaded_model = pickle.load(open(list_model[1], 'rb'))\n",
    "\n",
    "        #khangvan\n",
    "        newdf= pd.DataFrame(dict(s1 = data, s2 = predicted)).reset_index()\n",
    "\n",
    "        newdf[\"newdata\"]=newdf['s1']+' '+newdf['s2']\n",
    "        newdata =newdf[\"newdata\"]\n",
    "\n",
    "    #     for doc, category in zip(data,vi_df ):\n",
    "    #         newdf4hs=data+\" \"+vi_df\n",
    "    #         print(newdf4hs)\n",
    "    #         newdata.append(newdf4hs)\n",
    "        predicted = loaded_model.predict((newdata))\n",
    "        list_predict.append(predicted)\n",
    "\n",
    "            \n",
    "#         ----------   \n",
    "        main=[]\n",
    "        # Vi\n",
    "        for doc, category in zip(data, list_predict[0]):\n",
    "    #         print('%r => %s' % (doc, category))\n",
    "            v='%r => %s' % (doc, category)\n",
    "    #         print(type(v))\n",
    "            main.append('%r => %s' % (doc, category))\n",
    "        #HS\n",
    "        for doc, category in zip(main, list_predict[1]):\n",
    "            print('%r => %s' % ((doc), category))\n",
    "\n",
    "        def check_score_df(mytest):\n",
    "            import pickle\n",
    "            mydf=copy.copy(mytest)\n",
    "            vi_df = pickle.load(open('VI_CLF_report.df', 'rb'))\n",
    "            hs_df = pickle.load(open('HS_CLF_report.df', 'rb'))\n",
    "            vi_df[\"vi\"]=vi_df.index\n",
    "            hs_df[\"hs\"]=hs_df.index\n",
    "            mydf =mydf.merge(vi_df, left_on='vi', right_on='vi')\n",
    "            # print(mydf.columns)\n",
    "            mydf.drop(columns=['precision','recall','support'],inplace=True)\n",
    "            mydf.rename(columns={\"f1-score\": \"vi_f1_score\"}, inplace=True)\n",
    "\n",
    "            mydf =mydf.merge(hs_df, left_on='hs', right_on='hs')\n",
    "            mydf.drop(columns=['precision','recall','support'],inplace=True)\n",
    "            mydf.rename(columns={\"f1-score\": \"hs_f1_score\"}, inplace=True)\n",
    "\n",
    "            def mynote(row):\n",
    "                vi_rate=row['vi_f1_score']\n",
    "                hs_rate=row['hs_f1_score']\n",
    "                cmt1= 'vi check' if vi_rate <0.5 else ''\n",
    "                cmt2= 'hs check' if hs_rate <0.5 else ''\n",
    "                print(cmt1)\n",
    "                print(cmt2)\n",
    "                \n",
    "                return cmt1+ ' ' +cmt2\n",
    "                \n",
    "            mydf['mynote']=mydf.apply(mynote, axis=1)\n",
    "\n",
    "            return mydf\n",
    "\n",
    "        vi=list_predict[0]\n",
    "        hs=list_predict[1]\n",
    "        en= eng_list\n",
    "        final_df= pd.DataFrame(vi,columns=[\"vi\"])\n",
    "        final_df['hs']=hs\n",
    "        final_df['en']=en\n",
    "        final_df['material_input']=material\n",
    "\n",
    "        cols=['material_input','en', 'vi','hs']\n",
    "        hidata=final_df[cols]\n",
    "        \n",
    "        returndata=check_score_df(hidata) #vi, hs, en\n",
    "        import datetime as dt     \n",
    "        date = dt.date.today()\n",
    "        returndata['loaddate']= pd.to_datetime('today')\n",
    "#         print(returndata)\n",
    "        return returndata\n",
    "\n",
    "    ## work now<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    @staticmethod\n",
    "    def saplinkinfo_multi(material):\n",
    "        \n",
    "        import xml.etree.ElementTree as ET\n",
    "        from urllib.request import urlopen\n",
    "        from xml.etree.ElementTree import parse\n",
    "        import time \n",
    "        import urllib.parse\n",
    "        import asyncio\n",
    "        start=time.time()\n",
    "        \n",
    "        def saplinkinfo_local(material='770112003'):\n",
    "            import xml.etree.ElementTree as ET\n",
    "            from urllib.request import urlopen\n",
    "            from xml.etree.ElementTree import parse\n",
    "            import time \n",
    "            import urllib.parse\n",
    "            start=time.time()\n",
    "        #     material='770112003'\n",
    "            # tree = ET.parse('saplink.xml')\n",
    "            tag=fr'''\n",
    "            <Z_DMS_MATERIAL_INFO>\n",
    "            <LANG>E</LANG>\n",
    "            <WERKS></WERKS>\n",
    "            <VALIDON>03/23/2015</VALIDON>\n",
    "            <MATNR>{material}</MATNR>\n",
    "            </Z_DMS_MATERIAL_INFO>\n",
    "            '''\n",
    "            encodetag=urllib.parse.quote_plus(tag)\n",
    "\n",
    "            query='http://home/saplink/PRD/default.asp?XDoc='\n",
    "\n",
    "            url =query+encodetag\n",
    "        #     print(url)\n",
    "\n",
    "            var_url = urlopen(url)\n",
    "            tree = parse(var_url)\n",
    "\n",
    "            # tree = ET.parse(url)\n",
    "            root = tree.getroot()\n",
    "            root.tag\n",
    "            # for child in root:\n",
    "            #     print(child.tag, child.attrib)\n",
    "\n",
    "            # [elem.tag for elem in root.iter()]\n",
    "            list_des=[]\n",
    "            material_description=\"\"\n",
    "            for description in root.iter('DESCRIPTION'):\n",
    "                material_description=description.text+ material[0:3]\n",
    "        #         print(description.text)\n",
    "                list_des.append(material_description)\n",
    "        #     print(\"run in seconds: %s\" % str(time.time()-start))\n",
    "            return list_des, material\n",
    "        \n",
    "    #     material='770112003'\n",
    "        # tree = ET.parse('saplink.xml')\n",
    "        list_name=[]\n",
    "        for item in range(len(material)):\n",
    "#             print(material[item])\n",
    "            eng_item= (saplinkinfo_local(material[item]))[0]\n",
    "#             print(eng_item)\n",
    "            list_name.append(eng_item[0])\n",
    "        eng_list=list_name\n",
    "        return eng_list\n",
    "    # saplinkinfo_multi(['GD4130-BK','287021700'])\n",
    "    \n",
    "    #instnace method\n",
    "    def get_pn_server(self):\n",
    "        self.pn_list= (self.read_server_request())['Material']\n",
    "#         print(self.pn_list)\n",
    "        return list(self.pn_list)\n",
    "\n",
    "    def pn_server_dichviet_hscode(self):\n",
    "        self.get_pn_server()\n",
    "        df=self.pn_dichviet_hscode()\n",
    "        self.save_temp_server(df)\n",
    "        print('done save file at server temp_hts_vi')\n",
    "    def pn_new_dichviet_hscode(self):\n",
    "#         self.get_pn_server()\n",
    "        df=self.pn_dichviet_hscode()\n",
    "        self.save_temp_server(df)\n",
    "        print('done save file at server temp_hts_vi')\n",
    "\n",
    "    @staticmethod\n",
    "    def update_server_master():\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pymssql://reports:reports@vnmacsdb:1433/ACS EE\")\n",
    "        myquery='''\n",
    "        insert into HTS_VI ( material_input, en, vi, hs, vi_f1_score, hs_f1_score, mynote, loaddate) \n",
    "        select * from temp_hts_vi where material_input not in (\n",
    "        select material_input from  HTS_VI where loaddate >= DATEADD(minute,-1,getdate())\n",
    "        \n",
    "        )\n",
    "        '''\n",
    "        engine.execute(myquery)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('update complete, then show top 10 record from server')\n",
    "        \n",
    "        sql_view=\"select top 10 * from HTS_VI order by loaddate desc\"\n",
    "        df = pd.read_sql(sql_view, engine)\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def read_server_request():\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pymssql://reports:reports@vnmacsdb:1433/ACS EE\")\n",
    "        df = pd.read_sql('select top 100 Material  from hts_vi where DescriptionVI is null or HTSCode is null', engine)\n",
    "#         df.head()\n",
    "#         self.data=list(df.Material)\n",
    "        return df\n",
    "    @staticmethod\n",
    "    def save_temp_server(newdf):\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pymssql://reports:reports@vnmacsdb:1433/ACS EE\")\n",
    "        newdf.to_sql(name=\"temp_hts_vi\", con=engine, if_exists='replace', index=False,\n",
    "                dtype={'input_data': sqlalchemy.String(),\n",
    "                       'en': sqlalchemy.Text(), \n",
    "                        'vi': sqlalchemy.types.NVARCHAR(length=100), \n",
    "                       'hs': sqlalchemy.String() ,\n",
    "                        'loaddate': sqlalchemy.DateTime(), \n",
    "    #                    'Amount LC': sqlalchemy.types.Float(precision=3, asdecimal=True), \n",
    "    #                    'Quantity': sqlalchemy.types.Numeric(),\n",
    "                       })\n",
    "        # engine = create_engine('mssql+pymssql://reports:reports@vnmacsdb:1433/ACS EE')\n",
    "        df = pd.read_sql('select * from temp_hts_vi ', engine)\n",
    "#         df.head()\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def check_bieuthue(code):\n",
    "        # dl.update_result_to_server()\n",
    "        my_report_name ='bieuthue2019'\n",
    "        df = pickle.load(open(my_report_name, 'rb'))\n",
    "        \n",
    "        print(df.loc[df['hscode']==code])\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------   \n",
    "\n",
    "dl=datalogic_hscode_vi()\n",
    "# dl.set_data_des(['GRYPHON D4130-BLACK,Corded,1D, Multi I/FGD4', 'GRYPHON GD4400, 2D, BLACK,5V            GD4'])\n",
    "# dl.des_dichviet()\n",
    "# dl.des_hscode()\n",
    "\n",
    "dl.set_data_pn([\n",
    "'131129100'\n",
    "    \n",
    "])\n",
    "\n",
    "# dl.pn_dichviet_hscode()\n",
    "\n",
    "# dl.set_data_des(['IC', 'FAB', 'FAB MANUAL, CABLE, IC'])\n",
    "# dl.des_dichviet_hscode()\n",
    "\n",
    "# dl.saplinkinfo_multi(['GD4130-BK','287021700'])\n",
    "# dl.get_pn_server()\n",
    "# dl.pn_server_dichviet_hscode()\n",
    "# dl.save_temp_server()\n",
    "\n",
    "# dl.pn_new_dichviet_hscode()\n",
    "# dl.check_bieuthue(84719010)\n",
    "dl.pn_dichviet_hscode()\n",
    "# dl.save_temp_server(dl.pn_dichviet_hscode())\n",
    "# dl.update_server_master()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN in Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"'CBL ASY,IBM,USB,POT,BARREL,DC PLUG,3.65M90A' => DÂY CÁP ĐIỆN\" => 85444922\n",
      "\"'LENSES HOLDER REWORKED                  131' => VỎ GIỮ THẤU KÍNH (HỢP KIM KẼM)\" => 79012000\n",
      "update complete, then show top 10 record from server\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_input</th>\n",
       "      <th>en</th>\n",
       "      <th>vi</th>\n",
       "      <th>hs</th>\n",
       "      <th>vi_f1_score</th>\n",
       "      <th>hs_f1_score</th>\n",
       "      <th>mynote</th>\n",
       "      <th>loaddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90A052345</td>\n",
       "      <td>CBL ASY,IBM,USB,POT,BARREL,DC PLUG,3.65M90A</td>\n",
       "      <td>DÂY CÁP ĐIỆN</td>\n",
       "      <td>85444922</td>\n",
       "      <td>0.907463</td>\n",
       "      <td>0.984894</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-21 16:05:14.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GD4130-BK</td>\n",
       "      <td>GRYPHON D4130-BLACK,Corded,1D, Multi I/FGD4</td>\n",
       "      <td>MÁY ĐỌC MÃ VẠCH</td>\n",
       "      <td>84719010</td>\n",
       "      <td>0.985833</td>\n",
       "      <td>0.992157</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-21 16:01:42.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GD4230-BK</td>\n",
       "      <td>GD4</td>\n",
       "      <td>MÁY ĐỌC MÃ VẠCH</td>\n",
       "      <td>84719010</td>\n",
       "      <td>0.985833</td>\n",
       "      <td>0.992157</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-21 16:01:25.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GD4430-BK</td>\n",
       "      <td>GRYPHON GD4400, 2D, BLACK,5V            GD4</td>\n",
       "      <td>MÁY ĐỌC MÃ VẠCH</td>\n",
       "      <td>84719010</td>\n",
       "      <td>0.985833</td>\n",
       "      <td>0.992157</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-21 16:01:25.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'131129100</td>\n",
       "      <td>'13</td>\n",
       "      <td>MÁY ĐỌC MÃ VẠCH</td>\n",
       "      <td>84719010</td>\n",
       "      <td>0.985833</td>\n",
       "      <td>0.992157</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-21 15:57:26.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GD4230-BK</td>\n",
       "      <td>GD4</td>\n",
       "      <td>MÁY ĐỌC MÃ VẠCH</td>\n",
       "      <td>84719010</td>\n",
       "      <td>0.985833</td>\n",
       "      <td>0.992157</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-21 15:57:04.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gd4130-bk</td>\n",
       "      <td>gd4</td>\n",
       "      <td>MÁY ĐỌC MÃ VẠCH</td>\n",
       "      <td>84719010</td>\n",
       "      <td>0.985833</td>\n",
       "      <td>0.992157</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-21 15:56:26.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>890005229</td>\n",
       "      <td>PART, GD45XX HANDLE BOARD 5V BASE       890</td>\n",
       "      <td>PHỤ KIỆN BẢNG MẠCH IN ĐIỆN TỬ</td>\n",
       "      <td>84733090</td>\n",
       "      <td>0.784173</td>\n",
       "      <td>0.962348</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-18 13:21:03.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>890005228</td>\n",
       "      <td>PART, GD45 MECHANICAL ASSY, BLACK, BASE 890</td>\n",
       "      <td>PHỤ KIỆN CỤM LẮP RÁP CƠ KHÍ</td>\n",
       "      <td>84733090</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.962348</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-18 13:13:16.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>720024400</td>\n",
       "      <td>MOUNTING KIT,MC-GM45                    720</td>\n",
       "      <td>BỘ PHỤ KIỆN ĐỂ TREO ĐẾ SẠC</td>\n",
       "      <td>84733090</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.962348</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-18 11:20:35.903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  material_input                                           en  \\\n",
       "0      90A052345  CBL ASY,IBM,USB,POT,BARREL,DC PLUG,3.65M90A   \n",
       "1      GD4130-BK  GRYPHON D4130-BLACK,Corded,1D, Multi I/FGD4   \n",
       "2      GD4230-BK                                          GD4   \n",
       "3      GD4430-BK  GRYPHON GD4400, 2D, BLACK,5V            GD4   \n",
       "4     '131129100                                          '13   \n",
       "5      GD4230-BK                                          GD4   \n",
       "6      gd4130-bk                                          gd4   \n",
       "7   890005229     PART, GD45XX HANDLE BOARD 5V BASE       890   \n",
       "8      890005228  PART, GD45 MECHANICAL ASSY, BLACK, BASE 890   \n",
       "9      720024400  MOUNTING KIT,MC-GM45                    720   \n",
       "\n",
       "                              vi        hs  vi_f1_score  hs_f1_score mynote  \\\n",
       "0                   DÂY CÁP ĐIỆN  85444922     0.907463     0.984894          \n",
       "1                MÁY ĐỌC MÃ VẠCH  84719010     0.985833     0.992157          \n",
       "2                MÁY ĐỌC MÃ VẠCH  84719010     0.985833     0.992157          \n",
       "3                MÁY ĐỌC MÃ VẠCH  84719010     0.985833     0.992157          \n",
       "4                MÁY ĐỌC MÃ VẠCH  84719010     0.985833     0.992157          \n",
       "5                MÁY ĐỌC MÃ VẠCH  84719010     0.985833     0.992157          \n",
       "6                MÁY ĐỌC MÃ VẠCH  84719010     0.985833     0.992157          \n",
       "7  PHỤ KIỆN BẢNG MẠCH IN ĐIỆN TỬ  84733090     0.784173     0.962348          \n",
       "8    PHỤ KIỆN CỤM LẮP RÁP CƠ KHÍ  84733090     0.800000     0.962348          \n",
       "9     BỘ PHỤ KIỆN ĐỂ TREO ĐẾ SẠC  84733090     0.941176     0.962348          \n",
       "\n",
       "                 loaddate  \n",
       "0 2019-10-21 16:05:14.407  \n",
       "1 2019-10-21 16:01:42.293  \n",
       "2 2019-10-21 16:01:25.513  \n",
       "3 2019-10-21 16:01:25.513  \n",
       "4 2019-10-21 15:57:26.680  \n",
       "5 2019-10-21 15:57:04.207  \n",
       "6 2019-10-21 15:56:26.273  \n",
       "7 2019-10-18 13:21:03.957  \n",
       "8 2019-10-18 13:13:16.523  \n",
       "9 2019-10-18 11:20:35.903  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl=datalogic_hscode_vi()\n",
    "dl.set_data_pn([\n",
    " '90A052345'\n",
    "    ,'131129100'\n",
    "    \n",
    "])\n",
    "dl.save_temp_server(dl.pn_dichviet_hscode())\n",
    "dl.update_server_master()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>loaddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mot</td>\n",
       "      <td>hai</td>\n",
       "      <td>2019-10-12 11:52:08.346330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ba</td>\n",
       "      <td>bon</td>\n",
       "      <td>2019-10-12 11:52:08.346330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b                   loaddate\n",
       "0  mot  hai 2019-10-12 11:52:08.346330\n",
       "1   ba  bon 2019-10-12 11:52:08.346330"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[\n",
    "    (\"mot\",\"hai\")\n",
    "    ,(\"ba\", \"bon\")\n",
    "]\n",
    "df=pd.DataFrame.from_records(data, columns=['a','b'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_now('HTSCODE_VI.sav','ADDENDUM,REG,MGL3400/3500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_now('HTSCODE_HS.sav','ADDENDUM,REG,MGL3400/3500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_vi_hs(\"ADDENDUM,REG,MGL3400/3500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    'ADDENDUM,REG,MGL3400/3500',\n",
    "    'ASSY MODULE FIREFLY DE2101-DL GS',\n",
    "    'OPTICAL CHAMBER SUBASSY PUL2 STD MIC',\n",
    "    'LOADCELL,30KG,SHEKEL,C72D',\n",
    "    'LOCKING SYST BASE ASSY LIGHT, CRADLE MIC',\n",
    "    'FAB, FE4629, CUMULUS ILLUMINATION 100',\n",
    "    'VF - 233 SCREW M1,4X0,3 L=4 TORX T3', \n",
    "    'CVL-1057 RS232 OUTPUT CABLE TC1200',\n",
    "    'IC STR91XF 16/32-BIT FLASH MCU LQFP128',\n",
    "  'CVL-1120 OUTPUT CABLE TC1200 SB4507'\n",
    "])\n",
    "predict_data_vi_hs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    'ADDENDUM,REG,MGL3400/3500',\n",
    "    'ASSY MODULE FIREFLY DE2101-DL GS',\n",
    "    'OPTICAL CHAMBER SUBASSY PUL2 STD MIC',\n",
    "    'LOADCELL,30KG,SHEKEL,C72D',\n",
    "    'LOCKING SYST BASE ASSY LIGHT, CRADLE MIC',\n",
    "    'FAB, FE4629, CUMULUS ILLUMINATION 100',\n",
    "    'VF - 233 SCREW M1,4X0,3 L=4 TORX T3', \n",
    "    'CVL-1057 RS232 OUTPUT CABLE TC1200',\n",
    "    'IC STR91XF 16/32-BIT FLASH MCU LQFP128',\n",
    "  'CVL-1120 OUTPUT CABLE TC1200 SB4507',\n",
    "    ' ASSY IC   '\n",
    "])\n",
    "predict_data_vi_hs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "'MEMOR 10 UPPER ENCLOSURE AND DISPLAY'\n",
    ",'MEMOR 10 LOWER ENCLOSURE'\n",
    ",'MEMOR 10 UPPER ENCLOSURE AND DISPLAY HC'\n",
    ",'MEMOR 10 LOWER ENCLOSURE HC'\n",
    ",'MEMOR 10 GSM ANTENNA AND FRAME EU (3PCS)'\n",
    ",'MEMOR 10 VIBRATOR (10 PCS)'\n",
    ",'MEMOR 10 RECEIVER (10 PCS)'\n",
    ",'MEMOR 10 CAMERA'\n",
    ",'MEMOR 10 READER'\n",
    ",'MEMOR 10 WIFI ANTENNA, SPEAKER AND FRAME'\n",
    ",'MEMOR 10 SCREWS AND CAP KIT (10 UNITS)'\n",
    ",'MEMOR 10 SIM FPC'\n",
    ",'MEMOR 10 READER HARNESS (10 PCS)'\n",
    ",'MEMOR 10 MAIN, A8, FOR PN 944350003 & 08'\n",
    ",'MEMOR 10 MAIN, A8, FOR PN 944350001 & 07'\n",
    "\n",
    "])\n",
    "predict_data_vi_hs(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['vi'],newdf['hs'],newdf['en']=predict_data_vi_hs_from_pn('GD4130-BK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_vi_hs_from_pn([\n",
    "'131118061',\n",
    "'292004761',\n",
    "'822002101',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_vi_hs_from_pn('161017090')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_score_df(mytest):\n",
    "    import pickle\n",
    "    mydf=copy.copy(mytest)\n",
    "    vi_df = pickle.load(open('VI_CLF_report.df', 'rb'))\n",
    "    hs_df = pickle.load(open('HS_CLF_report.df', 'rb'))\n",
    "    vi_df[\"vi\"]=vi_df.index\n",
    "    hs_df[\"hs\"]=hs_df.index\n",
    "    mydf =mydf.merge(vi_df, left_on='vi', right_on='vi')\n",
    "    # print(mydf.columns)\n",
    "    mydf.drop(columns=['precision','recall','support'],inplace=True)\n",
    "    mydf.rename(columns={\"f1-score\": \"vi_f1_score\"}, inplace=True)\n",
    "\n",
    "    mydf =mydf.merge(hs_df, left_on='hs', right_on='hs')\n",
    "    mydf.drop(columns=['precision','recall','support'],inplace=True)\n",
    "    mydf.rename(columns={\"f1-score\": \"hs_f1_score\"}, inplace=True)\n",
    "\n",
    "    def mynote(row):\n",
    "        vi_rate=row['vi_f1_score']\n",
    "        hs_rate=row['hs_f1_score']\n",
    "        cmt1= 'vi check' if vi_rate <0.5 else ''\n",
    "        cmt2= 'hs check' if hs_rate <0.5 else ''\n",
    "        return cmt1+ ' ' +cmt2\n",
    "    mydf['mynote']=mydf.apply(mynote, axis=1)\n",
    "\n",
    "    return mydf\n",
    "\n",
    "check_score_df(mytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_vi_hs_from_pn(['019260044','939501108','294100501'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_vi_hs_from_pn([\n",
    "    '684140024',\n",
    "    'GD4520-BKK1S',\n",
    "    '100310690',\n",
    "    '5-2913',\n",
    "    '705004530'\n",
    " \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_vi_hs_from_pn([\n",
    "'890006080'\n",
    ",'890006165'\n",
    ",'890005245'\n",
    ",'937900012'\n",
    ",'937900008'\n",
    ",'937900010'\n",
    ",'890006166'\n",
    ",'890006167'\n",
    ",'890006519'\n",
    ",'911350047'\n",
    ",'710040101'\n",
    ",'710040300'\n",
    ",'700291204'\n",
    " \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data_vi_hs_from_pn([\n",
    "'890006080'\n",
    ",'890006165'\n",
    ",'890005245'\n",
    ",'937900012'\n",
    ",'937900008'\n",
    ",'937900010'\n",
    ",'890006166'\n",
    ",'890006167'\n",
    ",'890006519'\n",
    ",'911350047'\n",
    ",'710040101'\n",
    ",'710040300'\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "# df['hs']\n",
    "# df['en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAPLINK MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ Data from ACS server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "from flask import request, jsonify\n",
    "from flask import Flask\n",
    "from flask_cors import CORS\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymssql\n",
    "import pandas as pd\n",
    "conn = pymssql.connect(server=\"vnmacsdb\", user=\"reports\",password=\"reports\", database='ACS EE')  # You can lookup the port number inside SQL server. \n",
    "\n",
    "## Hey Look, college data\n",
    "stmt = \"select top 100 Material  from hts_vi where DescriptionVI is null or HTSCode is null \"\n",
    "# Excute Query here\n",
    "df = pd.read_sql(stmt,conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import pyodbc\n",
    "engine = sqlalchemy.create_engine(\"mssql+pymssql://reports:reports@vnmacsdb:1433/ACS EE\")\n",
    "# newdf=newdf.head(5)\n",
    "# newdf.to_sql(name=\"temp_testlog\", con=engine, if_exists='replace', index=False,\n",
    "#             dtype={'test_datetime': sqlalchemy.DateTime(), \n",
    "#                    'Pass_Fail': sqlalchemy.String(), \n",
    "#                     'Station': sqlalchemy.String(), \n",
    "#                    'ACS_Serial': sqlalchemy.String() \n",
    "# #                     'Pstng Date': sqlalchemy.DateTime(), \n",
    "# #                    'Amount LC': sqlalchemy.types.Float(precision=3, asdecimal=True), \n",
    "# #                    'Quantity': sqlalchemy.types.Numeric(),\n",
    "#                    })\n",
    "# # engine = create_engine('mssql+pymssql://reports:reports@vnmacsdb:1433/ACS EE')\n",
    "df = pd.read_sql('select top 100 Material  from hts_vi where DescriptionVI is null or HTSCode is null', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=predict_data_vi_hs_from_pn(df.Material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.to_sql(name=\"temp_hts_vi\", con=engine, if_exists='replace', index=False,\n",
    "            dtype={'input_data': sqlalchemy.String(),\n",
    "                   'en': sqlalchemy.Text(), \n",
    "                    'vi': sqlalchemy.String(), \n",
    "                   'hs': sqlalchemy.String() \n",
    "#                     'Pstng Date': sqlalchemy.DateTime(), \n",
    "#                    'Amount LC': sqlalchemy.types.Float(precision=3, asdecimal=True), \n",
    "#                    'Quantity': sqlalchemy.types.Numeric(),\n",
    "                   })\n",
    "# engine = create_engine('mssql+pymssql://reports:reports@vnmacsdb:1433/ACS EE')\n",
    "df = pd.read_sql('select * from temp_hts_vi ', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"840\" height=\"460\" controls=\"\">\n",
       "<source src=\"https://share.vidyard.com/watch/a3xSRmAeGz5nrwSQMMPd2U?\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"840\" height=\"460\" controls=\"\">\n",
    "<source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(\"https://share.vidyard.com/watch/a3xSRmAeGz5nrwSQMMPd2U?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>child1</td>\n",
       "      <td>1-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>child2</td>\n",
       "      <td>1-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>chile3</td>\n",
       "      <td>1-2-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>mother2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>child4</td>\n",
       "      <td>1-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level     name   path\n",
       "0     1   father      1\n",
       "1     1   mother      1\n",
       "2     2   child1    1-2\n",
       "3     2   child2    1-2\n",
       "4     3   chile3  1-2-3\n",
       "5     1  mother2      1\n",
       "6     2   child4    1-2"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cols=['level', 'name','path']\n",
    "data=[\n",
    "    ('1', 'father','1'),\n",
    "    ('1', 'mother','1'),\n",
    "    ('2', 'child1','1-2'),\n",
    "    ('2', 'child2','1-2'),\n",
    "    ('3', 'chile3','1-2-3'),\n",
    "    ('1', 'mother2','1'),\n",
    "    ('2', 'child4','1-2'),\n",
    "    \n",
    "]\n",
    "mydf= pd.DataFrame.from_records(data, columns=cols)\n",
    "mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>Hierarchy Name</th>\n",
       "      <th>Hierarchy Node ID</th>\n",
       "      <th>Hierarchy Level</th>\n",
       "      <th>Hierarchy Node Desc</th>\n",
       "      <th>Node Higher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>L110</td>\n",
       "      <td>1072</td>\n",
       "      <td>2</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L1100</td>\n",
       "      <td>992</td>\n",
       "      <td>3</td>\n",
       "      <td>Level 3 A</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L1101</td>\n",
       "      <td>994</td>\n",
       "      <td>3</td>\n",
       "      <td>Level 3 B</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L1102</td>\n",
       "      <td>997</td>\n",
       "      <td>3</td>\n",
       "      <td>Level 3 C</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L1103</td>\n",
       "      <td>1013</td>\n",
       "      <td>4</td>\n",
       "      <td>Level 4 1</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>L1104</td>\n",
       "      <td>1014</td>\n",
       "      <td>5</td>\n",
       "      <td>Level 5 A</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num Hierarchy Name  Hierarchy Node ID  Hierarchy Level Hierarchy Node Desc  \\\n",
       "0    1           L110               1072                2             Level 2   \n",
       "1    2          L1100                992                3           Level 3 A   \n",
       "2    3          L1101                994                3           Level 3 B   \n",
       "3    4          L1102                997                3           Level 3 C   \n",
       "4    5          L1103               1013                4           Level 4 1   \n",
       "5    6          L1104               1014                5           Level 5 A   \n",
       "\n",
       "   Node Higher  \n",
       "0            1  \n",
       "1         1072  \n",
       "2         1072  \n",
       "3         1072  \n",
       "4          992  \n",
       "5         1013  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strcol='num,Hierarchy Name,Hierarchy Node ID,Hierarchy Level,Hierarchy Node Desc,Node Higher'\n",
    "\n",
    "strdata='''\n",
    "0,L1,1,1,Top level,#\n",
    "1,L110,1072,2,Level 2,1\n",
    "2,L1100,992,3,Level 3 A,1072\n",
    "3,L1101,994,3,Level 3 B,1072\n",
    "4,L1102,997,3,Level 3 C,1072\n",
    "5,L1103,1013,4,Level 4 1,992\n",
    "6,L1104,1014,5,Level 5 A,1013\n",
    "'''\n",
    "\n",
    "cols=strcol.split(',')\n",
    "# cols\n",
    "\n",
    "# strdata.split().tolist()\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv(StringIO(strdata), sep=',')\n",
    "df.columns=cols\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lvl1</th>\n",
       "      <th>lvl1desc</th>\n",
       "      <th>lvl2</th>\n",
       "      <th>lvl2desc</th>\n",
       "      <th>lvl3</th>\n",
       "      <th>lvl3desc</th>\n",
       "      <th>lvl4</th>\n",
       "      <th>lvl4desc</th>\n",
       "      <th>lvl5</th>\n",
       "      <th>lvl5desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1072</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>994</td>\n",
       "      <td>Level 3 B</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1072</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>997</td>\n",
       "      <td>Level 3 C</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1072</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>992</td>\n",
       "      <td>Level 3 A</td>\n",
       "      <td>1013</td>\n",
       "      <td>Level 4 1</td>\n",
       "      <td>1014</td>\n",
       "      <td>Level 5 A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lvl1 lvl1desc  lvl2 lvl2desc  lvl3   lvl3desc  lvl4   lvl4desc  lvl5  \\\n",
       "0                1072  Level 2   994  Level 3 B                          \n",
       "1                1072  Level 2   997  Level 3 C                          \n",
       "2                1072  Level 2   992  Level 3 A  1013  Level 4 1  1014   \n",
       "\n",
       "    lvl5desc  \n",
       "0             \n",
       "1             \n",
       "2  Level 5 A  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find max hierarchy level\n",
    "mx = df['Hierarchy Level'].max()\n",
    "\n",
    "# identify terminal items\n",
    "last = df[~df['Hierarchy Node ID'].isin(pd.to_numeric(df['Node Higher'],\n",
    "                                                      errors='coerce'))]\n",
    "\n",
    "# build a list for any terminal items with all of its parents\n",
    "data = []\n",
    "for _, row in last.iterrows():\n",
    "    # initialize row\n",
    "    hrow= {'lvl'+str(i+1)+ext: '' for i in range(mx) for ext in ['', 'desc']}\n",
    "    # populate lvli and lvlidesc for the item and its parents\n",
    "    for lvl in range(row['Hierarchy Level'], 0, -1):\n",
    "        hrow['lvl'+str(lvl)] = row['Hierarchy Node ID']\n",
    "        hrow['lvl'+str(lvl) + 'desc'] = row['Hierarchy Node Desc']\n",
    "        # process parent until top level\n",
    "        try:\n",
    "            row = df[df['Hierarchy Node ID']==int(row['Node Higher'])].iloc[0]\n",
    "        except:\n",
    "            break\n",
    "    data.append(hrow)\n",
    "\n",
    "# build the resulting dataframe\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   534  100   534    0     0    683      0 --:--:-- --:--:-- --:--:--   683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'postgres_passwd',\n",
       " 'testrun',\n",
       " 'testrun2']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/khangvan/py/master/test.py\n",
    "import test\n",
    "\n",
    "dir(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hii'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.testrun2()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
